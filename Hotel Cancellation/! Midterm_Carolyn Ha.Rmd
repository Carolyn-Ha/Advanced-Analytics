---
title: "! Midterm - Carolyn Ha"
output:
  html_document:
    toc: true
    toc_float: true
    theme: united
    highlight: tango
author: "Carolyn Ha"
date: "2023-11-09"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, cache=TRUE}
library(caret)
library(class)
library(neuralnet)
library(kernlab)
library(C50)
library(tidyr)
library(dplyr)
library(janitor)
```


# Section 1: Question 2

## Question 2-1.
*Why do we expect the Kappa statistics for your second level decision tree model to be better than any of the first level models?*

**Answer)**

Given the cost information provided, the decision to expect the Kappa statistics for the second level decision tree model to be better than any of the first level models can be explained in terms of error costs and how the second level model is designed to minimize the overall financial impact.


**(1) Cost-Sensitive Learning at Second Level:**
  The second level decision tree is designed to take into account the specific costs associated with different types of errors (false positives and false negatives).

  The cost matrix is crucial in this context, as it allows the model to weigh the consequences of different types of misclassifications.
By incorporating the cost matrix, the second level model is explicitly trained to minimize the financial impact of hotel cancellations, considering the revenue loss and the additional cost incurred for unoccupied rooms.

  The cost associated with a false negative, where an unoccupied hotel room night results in a revenue loss of $200, differs significantly from the cost of a false positive. A false positive leads to the costly process of securing space for customers in a competitor hotel, incurring an expense of $800 per room night. Consequently, a false positive is four times more expensive than a false negative. To align the overall cost, I conducted experiments with various error costs to achieve a 4:1 ratio of false negative to false positive predictions, considering the accounting cost ratio of 1:4.

  It's essential to recognize that error costs consider the potential for misclassification, whereas accounting costs reflect the actual revenue loss or expenses incurred by the company. As the model lacks information about the accounting costs, I conducted experiments by adjusting error costs to modify the false negative to false positive ratio. This experimentation was crucial in achieving a balance that aligns with the 1:4 accounting cost ratio. Thus, the second-level model's capacity to integrate error costs significantly contributes to its higher Kappa statistics.



**(2) Error Correction and Aggregation:**
  The second level decision tree acts as a meta-model, combining the predictions of multiple first level models (Logistic Regression, KNN, ANN, SVM, and DT).
  
  The ensemble nature of the second level model can help correct errors made by individual first level models. If one model tends to overpredict cancellations and another underpredicts, the second level model can balance these tendencies, leading to more accurate predictions overall. Thus, leveraging a Decision Tree as the second level model enables the amalgamation of optimal decision features derived from all the base models. 

  
**(3) Consideration of Revenue and Cost Dynamics:**
  The second level model might be optimized specifically to minimize the financial impact outlined in the cost information.
  
  By incorporating the cost information into the model training process, the second level decision tree is expected to make predictions that are not only accurate in terms of hotel cancellations but also financially prudent.
  
  The cost information highlights the dynamic nature of revenue and costs associated with hotel cancellations.
The second level model, with the cost matrix, is better equipped to understand and leverage this dynamic information, leading to predictions that align more closely with the financial goals of the hotel.

In summary, by explicitly incorporating error costs, utilizing a cost matrix, and aggregating information from multiple first level models, the second level decision tree is expected to provide predictions that are not only accurate in terms of hotel cancellations but also considerate of the financial implications, leading to a better overall Kappa statistic.




## Question 2-2. 
*Build your second level model using Logistic Regression, build a Confusion Matrix. Did you get the same performance as Decision Tree as second level model? Why the difference?* 

```{r}
hotel_preds <- read.csv("hotel_preds.csv")
```

```{r, cache=TRUE}
#1) training - testing dataset
set.seed(12345)
tree_rows <- sample(1:nrow(hotel_preds), 0.7*nrow(hotel_preds))

tree_train <- hotel_preds[tree_rows, ]
tree_test <- hotel_preds[-tree_rows, ]
error_cost <- matrix(c(0, 1.5, 1,0), nrow=2)

#2) building the model
glm_basemodel <- glm(true ~., data=tree_train, family="binomial")
logistic_model_step <- step(glm_basemodel, direction="backward", trace=0)

#3) making prediction
glm_baseprediction <- predict(logistic_model_step, tree_test, type='response')
bin_prediction <- ifelse(glm_baseprediction >=0.3, 1, 0)

#4) evaluating the model
confusionMatrix(as.factor(bin_prediction), as.factor(tree_test$true), positive ="1")
```

**[Second Level Decision Tree]**

- Accuracy: 0.8618
- False Negative(cost: 200): 396
- False Positive(cost: 800): 223
- Kappa: 1262
- **Total cost**: 200X396 + 223X800 = 257600

**[Second Level Logistic Regression]**

- Accuracy: 0.8651
- False Negative(cost: 200): 237
- False Positive(cost: 800): 367
- Kappa: 0.7154
- **Total Cost**: 237X200 + 367X800 = 341000

  I didn't get the same performance as the second level decision tree. The total cost of the second level logistic regression is higher than that of the second level decision tree, even though the logistic regression model exhibits a higher Kappa statistic. This discrepancy can be attributed to several factors.

- Firstly, the second level **decision tree possesses the capability to explicitly incorporate error costs into the model-building process.** This allows the decision tree to individually assign costs to each type of misclassification, tailoring its decisions to minimize the total associated cost. In contrast, logistic regression relies on a fixed threshold (default at 0.5) for classification, without the inherent ability to explicitly account for different costs associated with false positives and false negatives.

  To address this limitation in logistic regression, one approach is to adjust the decision threshold. By varying the threshold, we indirectly consider the concept of error costs. For instance, lowering the threshold increases sensitivity but might result in more false positives. Conversely, raising the threshold increases specificity but might lead to more false negatives. This adjustment aims to find the optimal operating point on the ROC curve, striking a balance between sensitivity and specificity based on the cost considerations of the specific problem.

  Despite this adjustment, logistic regression might still fall short of the nuanced cost considerations achievable by the decision tree, which can explicitly assign varying costs to different misclassification types during its model-building process. Consequently, the decision tree, by considering the accounting cost and adjusting for error costs, yields a lower total cost compared to logistic regression.

- **Non-linearity in Data:** Logistic regression assumes a linear relationship between the predictors and the log-odds of the response. If the underlying relationship is highly non-linear, a decision tree, which is capable of capturing non-linear patterns, may outperform logistic regression.


- Considering the influence of feature interactions is vital when building predictive models, and it can be a factor contributing to differences in performance between models like Logistic Regression and Decision Trees. The Decision Tree's natural capacity to capture interactions may be advantageous in scenarios where features work together in a non-additive manner to influence the outcome.



# Section 2: Question 3

## Question 3-1. 
*If you are a hotel manager and you receive the hotel cancellation predicton analysis including the final Confusion Matrix, how will you use it to improve your operations and profitability?*

**Answer)**

1) **Mitigating Revenue Loss**: Using predictions of False Negatives and False Positives, the hotel manager can establish the overbooking threshold by employing the following steps. This allows them to minimize costs associated with room vacancies and operating expenses incurred when booking rooms from competing companies.

- **(1)	Calculate the Expected Revenue Loss from Unoccupied Rooms:**
Identify the number of rooms that are expected to remain unoccupied due to cancellations. Multiply this by the revenue loss per unoccupied room night. For example, if you expect 10 unoccupied room nights and the revenue loss is $200 per night, the expected revenue loss would be 10 * $200 = $2,000.
- **(2)	Estimate the Cost of Redirecting Customers to Competitor Hotels:** Identify instances where your bookings outnumber available rooms. Estimate the number of customers who need to be redirected and multiply this by the cost of redirecting to a competitor hotel. For instance, if you need to redirect 5 customers and the cost is $800 per room night, the cost of redirection would be 5 * $800 = $4,000.
- **(3)	Calculate Net Revenue Impact:** Subtract the revenue loss from unoccupied rooms and the cost of redirection from the potential revenue to get the net revenue impact. For example, if the expected revenue loss is $2,000 and the cost of redirection is $4,000, the net revenue impact would be -$2,000 (indicating a loss).
- **(4)	Evaluate the Trade-off:** Compare the net revenue impact with the expected revenue from fully occupied rooms. This will help in evaluating the trade-off between overbooking and potential revenue loss.
- **(5)	Optimize Overbooking Threshold:** Adjust the overbooking threshold to find the balance that minimizes the overall cost, considering both the revenue loss from unoccupied rooms and the cost of redirecting customers.
- **(6)	Incorporate Second-Level Decision Tree with Cost Matrix:**
If you've implemented a second-level Decision Tree with a Cost Matrix, assess its impact on reducing the overall cost. Evaluate whether the refined model improves decision-making regarding overbooking.
- **(7)	Sensitivity Analysis:** Conduct sensitivity analysis to understand how variations in the number of cancellations or the cost of redirection affect the overall cost. This can help in identifying potential risks and uncertainties in the calculations.


2) Other ways to use the prediction model is as follows:

- **Optimizing Room Inventory:** Analyze True Positives to release rooms back into inventory when cancellations are accurately predicted. Conversely, investigate False Positives to understand and address overestimations.
- **Dynamic Pricing Strategies:** Adjust room rates based on cancellation predictions. Implement dynamic pricing strategies to stimulate demand or offer discounts when the risk of overbooking is low.
- **Customer Communication:** Proactively communicate with customers in case of potential cancellations. Offer alternatives or incentives to mitigate the impact on guest satisfaction and loyalty.
- **Refining Booking Policies:** Evaluate and refine booking policies based on prediction insights. Implement policies that encourage early cancellations or provide flexible options to reduce the impact of last-minute cancellations.



## Question 3-2. Specific Example

From your second level dataset, choose row numbers 101 thourgh 200 (so a total of 100 rows). Assume that you don't know the "is_cancelled" variable for these 100 reservations. Further assume that these 100 reservations are scheduled to arrive on the same day in future. You expect that you will have 100 rooms available for guests to check-into on that day. So if all of them show up then you will be full to capacity and be a happy hotel manager.

How many of these 100 reservations would you expect to be cancelled? Use your second level Decision Tree model to predict how many of these reservations will end up being cancelled. Note that you don't need to train a new model - use your final second level decision tree model to make the prediction.

How can you improve your profitability now that you have the answer to the question above.

```{r}
hotel_preds2 <- hotel_preds[101:200, ]
DT_model <- readRDS("DT_model_second_level.rds")

#2) predicting
library(C50)
DT_prediction <- predict(DT_model, hotel_preds2)
summary(DT_prediction)

#3) evaluating the model
library(caret)
confusionMatrix(as.factor(DT_prediction), as.factor(hotel_preds2$true), positive='1')
```

Based on the model I created, I expect that there's going to be 37 cancellations. 

**Answer)**
  Given the prediction from the second-level Decision Tree model, which anticipates a cancellation rate of 37 out of 100 reservations, and the additional information derived from the confusion matrix (actual cancellations being 33(TP) out of 37(TP+FP)), we can make strategic decisions to manage overbooking and improve profitability.

**[Overbooking Strategy]**

- **prediction of cancellation** = 37/100
- **actual cancellation** = 33/37 = TP/(FP+TP)
- **possible overbooking** = 37*33/37 = prediction of cancellation X actual cancellation

*Expected Cancellations:* Based on the model's prediction and the actual cancellation rate, it's anticipated that approximately 33% of the reservations (33 out of 100) will result in cancellations.
Overbooking Calculation:

*Overbooking Calculation:* Using the overbooking calculation formula, we find that overbooking by 33 more reservations is feasible (37 * 33/37 = 33).

*Iterative Overbooking Process:* Overbooking by 33 reservations is the initial step. However, recognizing that some of the overbooked guests may still cancel or not show up, this becomes an iterative process. Subsequent adjustments can be made based on the actual cancellations observed.




**[Expected Cost Based on Confusion Matrix]**

- **expected cost based on confusion matrix** = FN/(FN+TP)X200 + FP(TN+FP)X800 = 8/41X200 + 4/59X800 = 93.26168

This means that, based on the model's predictions and the associated confusion matrix, the expected cost incurred due to false negatives and false positives is approximately $93.26.
